{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-multi-object-instance-segmentation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM3xWvmVR9zii13ZilULY96",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/modern-computer-vision-with-pytorch/blob/main/10-applications-of-object-detection-and-segmentation/1_multi_object_instance_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdmPYDJ3nxyA"
      },
      "source": [
        "## Multi-object instance segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gU7u_gsnydl"
      },
      "source": [
        "**Detectron2** is a platform built by the Facebook team. **Detectron2** includes high-quality implementations of state-of-the-art object detection algorithms, including DensePose of the Mask R-CNN model family. The original Detectron framework was written in Caffe2, while the **Detectron2** framework is written using PyTorch.\n",
        "\n",
        "Detectron2 supports a range of tasks related to object detection. \n",
        "\n",
        "Like the original Detectron, it supports object detection with boxes and instance segmentation masks, as well as human pose prediction. \n",
        "\n",
        "Beyond that, Detectron2 adds support for semantic segmentation and panoptic segmentation (a task that combines both semantic and instance segmentation). By leveraging Detectron2, we are able to build object detection, segmentation, and pose estimation in a few lines of code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELT3AA7Rob1Y"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYcO1M0Joc7t"
      },
      "source": [
        "%%shell\n",
        "\n",
        "pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "pip install -qU openimages torch_snippets\n",
        "pip install git+git://github.com/waspinator/pycococreator.git@0.2.0\n",
        "pip install pycocotools\n",
        "pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n",
        "pip install pyyaml==5.1 pycocotools>=2.0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCrGAOrrohlV"
      },
      "source": [
        "from torch_snippets import *\n",
        "from openimages.download import _download_images_by_id\n",
        "import zipfile\n",
        "import datetime\n",
        "import json\n",
        "\n",
        "from pycococreatortools import pycococreatortools\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.utils.visualizer import ColorMode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4jz29Abpfkc"
      },
      "source": [
        "!wget -O train-annotations-object-segmentation.csv -q https://storage.googleapis.com/openimages/v5/train-annotations-object-segmentation.csv\n",
        "!wget -O classes.csv -q https://raw.githubusercontent.com/openimages/dataset/master/dict.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gnBvx4fpsjE"
      },
      "source": [
        "## Fetching and preparing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKULr4Qnpsr1"
      },
      "source": [
        "We will be working on the images that are available in the Open Images dataset provided by Google at https://storage.googleapis.com/openimages/web/index.html.\n",
        "\n",
        "We will learn about fetching only the required images and not\n",
        "the entire dataset. Note that this step is required, as the dataset size prohibits a typical user who might not have extensive resources from building a model.\n",
        "\n",
        "Let's specify the classes that we want our model to predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvNQC6gUrpa7"
      },
      "source": [
        "required_classes = \"person,dog,bird,car,elephant,football,jug,laptop,Mushroom,Pizza,Rocket,Shirt,Traffic sign,Watermelon,Zebra\"\n",
        "required_classes = [c.lower() for c in required_classes.lower().split(\",\")]\n",
        "\n",
        "classes = pd.read_csv(\"classes.csv\", header=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}